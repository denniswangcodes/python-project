df = pd.DataFrame([[2,3,4], [4,5,6], [7,8,9]], columns=["A","B","C"], index=["x","y","z"])
df.head()
df.columns
df.index
df.describe()
df.info()
df.nunique()
df['A'].unique()
df.shape

coffee = pd.read_csv(path)
coffee = pd.read_parquet(path)
coffee = pd.read_excel(path)
coffee.sample(10, random_state=1)
coffee.head()
coffee.tail()
coffee.loc[row, column]
coffee.loc[5:8, ["Day", "Units Sold"]]
coffee.iloc[:, [0,2]] #only using rows columns index value
coffee.sort_values(["Units Sold", "Coffee Type"], ascending=[False]) # or ascending=[0,1]
for index, row in coffee.iterrows():
	print(index)
coffee = coffee.copy()

import numpy as np
coffee['price'] = 4.99
coffee['new_price'] = np.where(coffee['Coffee Type']=='Espresso', 3.99, 5.99)
coffee.drop(columns=['price'], inplace=True)
coffee = coffee.drop(columns=['price'])
coffee = coffee[['Day', 'Coffee', 'Units Sold']] # implicit way to drop columns
coffee.rename(columns={'price':'new price'})

bios.loc[(bios['height_cm'] > 215) & (bios['born_country']=="USA")]
bios[bios['name'].str.contains("Keith|Patrick", case=False)]
bios_new = bios.copy()
bios_new['first_name'] = bios_new['name'].str.split(' ').str[0]
bios_new.query('first_name == "Kieth"')
bios_new['born_date'] = pd.to_datetime(bios_new['born_date'], format="%Y-%m-%d")
bios_new['born_year'] = bios_new['born_date'].dt.year
bios_new.to_csv(path, index=False)
bios['height_cateogry'] = bios['height_cm'].apply(lambda x: 'Short' if x < 165 else ('Average' if x < 185 else 'Tall'))
def categorize_athlete(row):
  if row['height_cm'] < 175 and row['weight_kg'] < 70:
    return 'Lightweight'
  else:
    return 'Heavyweight'
bios['Category'] = bios.apply(categorize_athlete, axis=1) #axis=1 row by row, 0 col by col

# merging and joining
nocs = pd.read_csv(path)
pd.merge(bios, nocs, left_on='born_country', right_on='NOC', how='inner', suffixes=["postA", "postB"])
usa = bios[bios['born_country']=='USA'].copy()
gbr = bios[bios['born_country']=='Great Britain'].copy()
new_df = pd.concat([usa, gbr])
combine_df = pd.merge(results, bios, on='athlete_id', how='left')

# null handling
coffee.loc[[0,1], 'Units Sold'] = np.nan
coffee.isna().sum()
coffee = coffee.fillna(0)
coffee.fillna(coffee['Units Sold'].mean()) # or .interpolate() to predict pattern
coffee.dropna() #drops full entire row
coffee.dropna(subset=['Units Sold'], inplace=True)
coffee[coffee['Units Sold'].notna()]

bios[bios['born_country']=='USA'].value_counts()
coffee.groupby(['coffee type'])['units sold'].sum() # or .agg({'units sold': 'sum', 'price': 'mean'})

# pivot table
pivot = coffee.pivot(columns='coffee type', index='day', values='revenue')
bios.groupby(bios['born_date'].dt.year)['name'].count().reset_index().sort_values('name', ascending=False)

# advanced functions
coffee['yesterday_revenue'] = coffee['revenue'].shift(2)
bios['height_rank'] = bios['height_cm'].rank()
bios.sort_values(['height_rank'], ascending=False)
bios.sort_values(['height_rank']).sample(10)[['name', 'height_rank']]
coffee['cumulative_revenue'] = coffee['revenue'].cumsum()
latte = coffee[coffee['coffee type']=="Latte"].copy()
latte['3 day'] = latte['units sold'].rolling(3).sum()
